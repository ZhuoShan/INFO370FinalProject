{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_car = pd.read_csv('cleanData/used_car_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_car_copy = used_car.copy()\n",
    "used_car_copy['Make'] = used_car_copy['Make'].str.upper()\n",
    "used_car_copy['Model'] = used_car_copy['Model'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchForMake = ['JEEP', 'CHEVROLET','HYUNDAI','NISSAN','HONDA','BMW','VOLKSWAGEN','GMC','FORD']\n",
    "used_car_copy = used_car_copy[used_car_copy.Make.str.contains('|'.join(searchForMake))]\n",
    "searchForModel = ['GRAND', 'WRANGLER','EQUINOXFWD','SANTA','ALTIMA2.5','ACCORD','3','JETTA','SILVERADO','SIERRA','F-1504WD','SUPER']\n",
    "used_car_copy = used_car_copy[used_car_copy.Model.str.contains('|'.join(searchForModel))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_car_copy['Original Price'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Original Price and Vehicle type to SUV\n",
    "used_car_copy.loc[(used_car_copy.Make == 'JEEP') & (used_car_copy.Model == 'GRAND'), 'Original Price'] = 31695\n",
    "used_car_copy.loc[(used_car_copy.Make == 'JEEP') & (used_car_copy.Model == 'GRAND'), 'Vehicle Type'] = 'SUV'\n",
    "used_car_copy.loc[(used_car_copy.Make == 'JEEP') & (used_car_copy.Model == 'WRANGLER'), 'Original Price'] = 28045\n",
    "used_car_copy.loc[(used_car_copy.Make == 'JEEP') & (used_car_copy.Model == 'WRANGLER'), 'Vehicle Type'] = 'SUV'\n",
    "used_car_copy.loc[(used_car_copy.Make == 'CHEVROLET') & (used_car_copy.Model == 'EQUINOXFWD'), 'Original Price'] = 31000\n",
    "used_car_copy.loc[(used_car_copy.Make == 'CHEVROLET') & (used_car_copy.Model == 'EQUINOXFWD'), 'Vehicle Type'] = 'SUV'\n",
    "used_car_copy.loc[(used_car_copy.Make == 'HYUNDAI') & (used_car_copy.Model == 'SANTA'), 'Original Price'] = 29800\n",
    "used_car_copy.loc[(used_car_copy.Make == 'HYUNDAI') & (used_car_copy.Model == 'SANTA'), 'Vehicle Type'] = 'SUV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Original Price and Vehicle type to Sedan\n",
    "used_car_copy.loc[(used_car_copy.Make == 'NISSAN') & (used_car_copy.Model == 'ALTIMA2.5'), 'Original Price'] = 31780\n",
    "used_car_copy.loc[(used_car_copy.Make == 'NISSAN') & (used_car_copy.Model == 'ALTIMA2.5'), 'Vehicle Type'] = 'Sedan'\n",
    "used_car_copy.loc[(used_car_copy.Make == 'HONDA') & (used_car_copy.Model == 'ACCORD'), 'Original Price'] = 27470\n",
    "used_car_copy.loc[(used_car_copy.Make == 'HONDA') & (used_car_copy.Model == 'ACCORD'), 'Vehicle Type'] = 'Sedan'\n",
    "used_car_copy.loc[(used_car_copy.Make == 'BMW') & (used_car_copy.Model == '3'), 'Original Price'] = 45000\n",
    "used_car_copy.loc[(used_car_copy.Make == 'BMW') & (used_car_copy.Model == '3'), 'Vehicle Type'] = 'Sedan'\n",
    "used_car_copy.loc[(used_car_copy.Make == 'VOLKSWAGEN') & (used_car_copy.Model == 'JETTA'), 'Original Price'] = 24500\n",
    "used_car_copy.loc[(used_car_copy.Make == 'VOLKSWAGEN') & (used_car_copy.Model == 'JETTA'), 'Vehicle Type'] = 'Sedan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Original Price and Vehicle type to Truck\n",
    "used_car_copy.loc[(used_car_copy.Make == 'CHEVROLET') & (used_car_copy.Model == 'SILVERADO'), 'Original Price'] = 38200\n",
    "used_car_copy.loc[(used_car_copy.Make == 'CHEVROLET') & (used_car_copy.Model == 'SILVERADO'), 'Vehicle Type'] = 'Truck'\n",
    "used_car_copy.loc[(used_car_copy.Make == 'GMC') & (used_car_copy.Model == 'SIERRA'), 'Original Price'] = 35900\n",
    "used_car_copy.loc[(used_car_copy.Make == 'GMC') & (used_car_copy.Model == 'SIERRA'), 'Vehicle Type'] = 'Truck'\n",
    "used_car_copy.loc[(used_car_copy.Make == 'FORD') & (used_car_copy.Model == 'F-1504WD'), 'Original Price'] = 34695\n",
    "used_car_copy.loc[(used_car_copy.Make == 'FORD') & (used_car_copy.Model == 'F-1504WD'), 'Vehicle Type'] = 'Truck'\n",
    "used_car_copy.loc[(used_car_copy.Make == 'FORD') & (used_car_copy.Model == 'SUPER'), 'Original Price'] = 33150\n",
    "used_car_copy.loc[(used_car_copy.Make == 'FORD') & (used_car_copy.Model == 'SUPER'), 'Vehicle Type'] = 'Truck'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_car_copy=used_car_copy.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gdp = pd.read_csv('cleanData/MAGDP2_2001_2017_ALL_AREAS.csv')\n",
    "#gdp = gdp[gdp['GeoName'].str.contains('CA', na = False)]\n",
    "gdp = gdp[gdp['Description'].str.contains('All industry total', na=False)].drop('GeoFIPS', axis=1).drop('Region', axis=1).drop('TableName', axis=1).drop('ComponentName', axis=1).drop('Unit', axis=1).drop('IndustryId', axis=1).drop('IndustryClassification', axis=1).drop('Description', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select car in top Ten most popular cities rank by sales\n",
    "\n",
    "#Houston = used_car_copy[used_car_copy['City'].str.contains('Houston')]\n",
    "#San_Antonio = used_car_copy[used_car_copy['City'].str.contains('San Antonio')]    \n",
    "#Louisville = used_car_copy[used_car_copy['City'].str.contains('Louisville')] \n",
    "#Jacksonville = used_car_copy[used_car_copy['City'].str.contains('Jacksonville')] \n",
    "#Austin = used_car_copy[used_car_copy['City'].str.contains('Austin')]                          \n",
    "#Columbia = used_car_copy[used_car_copy['City'].str.contains('Columbia')]                  \n",
    "#Raleigh = used_car_copy[used_car_copy['City'].str.contains('Raleigh')]                             \n",
    "#Orlando = used_car_copy[used_car_copy['City'].str.contains('Orlando')]   \n",
    "#Colorado = used_car_copy[used_car_copy['City'].str.contains('Colorado')]       \n",
    "#Philadelphia = used_car_copy[used_car_copy['City'].str.contains('Philadelphia')]    \n",
    "#San_Francisco = used_car_copy[used_car_copy['City'].str.contains('San Francisco')]    \n",
    "\n",
    "\n",
    "#Houston.drop(Houston.columns[0],axis=1,inplace=True)\n",
    "#San_Antonio.drop(San_Antonio.columns[0],axis=1,inplace=True)\n",
    "#Louisville.drop(Louisville.columns[0],axis=1,inplace=True)\n",
    "#Jacksonville.drop(Jacksonville.columns[0],axis=1,inplace=True)\n",
    "#Austin.drop(Austin.columns[0],axis=1,inplace=True)\n",
    "#Columbia.drop(Columbia.columns[0],axis=1,inplace=True)\n",
    "#Raleigh.drop(Raleigh.columns[0],axis=1,inplace=True)\n",
    "#Orlando.drop(Orlando.columns[0],axis=1,inplace=True)\n",
    "#Colorado.drop(Colorado.columns[0],axis=1,inplace=True)\n",
    "#Philadelphia.drop(Philadelphia.columns[0],axis=1,inplace=True)\n",
    "#San_Francisco.drop(San_Francisco.columns[0],axis=1,inplace=True)\n",
    "#Top_cities = pd.concat([Houston, San_Antonio, Louisville, Jacksonville, Austin, Columbia, Raleigh, Orlando, Colorado, Philadelphia, San_Francisco])\n",
    "\n",
    "    \n",
    "#CAUsedCar = used_car_copy[used_car_copy['State'].str.contains('CA')]\n",
    "\n",
    "#WAUsedCar.drop(WAUsedCar.columns[0],axis=1,inplace=True)\n",
    "#CAUsedCar.drop(CAUsedCar.columns[0],axis=1,inplace=True)\n",
    "\n",
    "#WAUsedCar['City'] = WAUsedCar['City'].str.upper()\n",
    "#WAUsedCarGrouped = WAUsedCar.groupby('City')\n",
    "#WAUsedCarGrouped.size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove cars are not made in the year of 2001 to 2017\n",
    "#CAUsedCar = CAUsedCar[(CAUsedCar['Year'] >2000) & (CAUsedCar['Year'] <2018)]\n",
    "\n",
    "#Top_cities = Top_cities[(Top_cities['Year'] >2000) & (Top_cities['Year'] <2018)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a column of service time \n",
    "Top_cities = used_car_copy\n",
    "Top_cities['serviceTime'] = 2018 - Top_cities['Year']\n",
    "#get depreciationRate and then drop price and original price\n",
    "Top_cities['DepreciationRate'] = Top_cities['Price']/Top_cities['Original Price']\n",
    "#CAUsedCar.drop(CAUsedCar.columns[0],axis=1,inplace=True)\n",
    "#CAUsedCar.drop(CAUsedCar.columns[6],axis=1,inplace=True)\n",
    "#drop make and model column\n",
    "#CAUsedCar.drop(CAUsedCar.columns[4],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CAUsedCar = CAUsedCar.drop(CAUsedCar[CAUsedCar.DepreciationRate > 1.0].index)\n",
    "Top_cities = Top_cities.drop(Top_cities[Top_cities.DepreciationRate > 1.0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top_cities['Gdp'] = 0\n",
    "Top_cities['City'] = Top_cities['City'].str.upper()\n",
    "gdp['GeoName'] = gdp['GeoName'].str.upper()\n",
    "for index,car in Top_cities.iterrows():\n",
    "    allGdp = gdp[(gdp['GeoName'].str.contains(car['City']))]\n",
    "    #col = [col for col in allGdp.columns if str(car['Year']) in col]\n",
    "    Gdp = allGdp['2017'].values.tolist()\n",
    "    if len(Gdp) > 0:\n",
    "        car['Gdp'] = Gdp[0]\n",
    "        Top_cities.at[index,'Gdp'] = float(Gdp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City\n",
       "Houston               779\n",
       "San Antonio           412\n",
       "Louisville            377\n",
       "Jacksonville          338\n",
       "Austin                337\n",
       "Columbia              337\n",
       "Raleigh               301\n",
       "Orlando               299\n",
       "Colorado Springs      287\n",
       "Philadelphia          273\n",
       "Puyallup              265\n",
       "Dallas                263\n",
       "Columbus              245\n",
       "Phoenix               231\n",
       "Las Vegas             226\n",
       "Charlotte             221\n",
       "Miami                 218\n",
       "Concord               204\n",
       "Tampa                 200\n",
       "Indianapolis          200\n",
       "Madison               191\n",
       "Fort Worth            181\n",
       "El Paso               175\n",
       "Oklahoma City         171\n",
       "Albuquerque           170\n",
       "Richmond              169\n",
       "Tucson                167\n",
       "Marietta              164\n",
       "Arlington             157\n",
       "Springfield           155\n",
       "                     ... \n",
       "Lemont                  1\n",
       "Tamarac                 1\n",
       "Country Club Hills      1\n",
       "Lehi                    1\n",
       "St Petersburg           1\n",
       "McLean                  1\n",
       "Mt. Kisco               1\n",
       "Spicewood               1\n",
       "Secaucus                1\n",
       "Seguin                  1\n",
       "Seminole                1\n",
       "Seneca Falls            1\n",
       "Shallotte               1\n",
       "Moss Point              1\n",
       "Morrisville             1\n",
       "Silsbee                 1\n",
       "Monrovia                1\n",
       "Beverly Hills           1\n",
       "Sodus                   1\n",
       "Christiansburg          1\n",
       "Cicero                  1\n",
       "Berwyn                  1\n",
       "South Lake Tahoe        1\n",
       "Millville               1\n",
       "Bergenfield             1\n",
       "Southborogh             1\n",
       "Middleburg Heights      1\n",
       "Medway                  1\n",
       "Bennettsville           1\n",
       "Eldridge                1\n",
       "Length: 2424, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_car_copy.groupby(['City']).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.read_csv('cityPopulation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = population[['Name','Population']][:10]\n",
    "population['Name'] = population['Name'].str.upper()\n",
    "population['Population'] = population['Population'].astype(str)\n",
    "population['Population'] = population['Population'].replace(',', '') \n",
    "for index, pop in population.iterrows():\n",
    "    pop['Population'] = pop['Population'].replace(',', '')\n",
    "    population['Population'][index] = int(float(pop['Population']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DALLAS', 'PHOENIX', 'PHILADELPHIA', 'HOUSTON', 'SAN ANTONIO',\n",
       "       'SAN DIEGO', 'CHICAGO', 'SAN JOSE', 'LOS ANGELES', 'NEW YORK'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalData = pd.merge(Top_cities, population, left_on='City', right_on='Name').drop('Name', axis = 1)\n",
    "finalData = finalData.drop('Original Price', axis=1).drop('Price', axis=1).drop('Make', axis=1).drop('Model', axis=1)\n",
    "finalData['City'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData.to_csv('finalData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse string \"2,340,814\" at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mpandas/_libs/src\\inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"2,340,814\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-bddb55502eed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinalData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Population'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinalData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Population\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[1;34m(arg, errors, downcast)\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[0mcoerce_numeric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'raise'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             values = lib.maybe_convert_numeric(values, set(),\n\u001b[1;32m--> 133\u001b[1;33m                                                coerce_numeric=coerce_numeric)\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/src\\inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"2,340,814\" at position 0"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
